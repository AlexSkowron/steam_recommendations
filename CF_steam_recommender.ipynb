{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam Recommender System project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will attempt to build a recommendation system for the video game store [Steam](https://store.steampowered.com/). I will use a collaborative filtering (CF) approach to build a recommendation system based on user interactions on the online platform. More specifically, I will utilize user video game purchases and playtime to build and compare different recommendation algorithms based on implicit feedback (rather than explicit user game ratings). This information can be retrieved via the official [Steam Web API](https://developer.valvesoftware.com/wiki/Steam_Web_API) for users with public community profile settings. For this exercise I will draw on [this](https://www.kaggle.com/datasets/tamber/steam-video-games) kaggle dataset, which contains 200k user interactions. In this project I train different memory-based and model-based recommendation algorithms and compare their performance on held-out data.\n",
    "\n",
    "Possible future directions for this project:\n",
    "- Add [more model evaluation methods](https://medium.com/@paul0/evaluating-recommender-systems-4915c22ad44a)\n",
    "- Implement parameter tuning for the different model\n",
    "- Implement a [deep-learning approach](https://www.kaggle.com/code/taruntiwarihp/recommender-system-deep-learning)\n",
    "- Compare and contrast with a content-based filtering approach and implement a [hybrid model](https://medium.com/@teddywang0202/implicit-feedback-recommendation-system-iv-hybrid-recommendation-f966b34e2bc9)\n",
    "- better method for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "import implicit\n",
    "from implicit.nearest_neighbours import bm25_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and convert to user-item matrix. Some models will be trained on binary user behavior (i.e., purchases) while others will further utilize playtime information as a proxy for confidence that the user likes a game. I will further filter out all users with only one item interaction since they add little value in building our recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/kkjdv1617vs81qrl4hfy9wzwbf__5q/T/ipykernel_21375/1707918476.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_purchase['rating'].replace(to_replace = 1, value = 0.01, inplace=True) # interpolate playtime with a small value reflectig low confidence that the user likes the game\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4945, 5126)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read steam_200k dataset into a dataframe\n",
    "df = pd.read_csv('./data/steam-200k.csv',names=('userID', 'itemID', 'label', 'rating', 'NA'))\n",
    "df = df.drop(['NA'], axis=1)\n",
    "\n",
    "# create df of playtimes (proxy for how much a user likes the game)\n",
    "df_play = df[df.label == 'play']\n",
    "df_play.index = df_play['itemID']\n",
    "\n",
    "# append purchased items that have not been played since these games should not be recommended.\n",
    "df_purchase = df[df.label == 'purchase']\n",
    "df_purchase.index = df_purchase['itemID']\n",
    "\n",
    "# interpolate playtime with a small value reflectig low confidence that the user likes the game (e.g., the user may have purchased the game in a bundle but never played it)\n",
    "df_purchase['rating'].replace(to_replace = 1, value = 0.01, inplace=True)\n",
    "\n",
    "purchase_only_idx = df_purchase.index.difference(df_play.index)\n",
    "\n",
    "df_play = pd.concat([df_play, df_purchase.loc[purchase_only_idx]]) # add purchased but not played games\n",
    "\n",
    "# clean up\n",
    "df_play.reset_index(inplace=True, drop = True)\n",
    "df_play = df_play.drop(['label'], axis=1)\n",
    "\n",
    "# create user-item matrix\n",
    "df_play = pd.pivot_table(df_play, values='rating', index='userID', columns='itemID')\n",
    "\n",
    "# filter out all users with only one game purchase\n",
    "df_play = df_play.loc[(df_play > 0).sum(axis=1) > 1]\n",
    "df_play = df_play.drop(df_play.columns[df_play.isna().all(axis=0)], axis=1) # remove games with no user interaction after filtering\n",
    "\n",
    "# replace NaN with 0 (needed for cosine similarity metric)\n",
    "df_play.fillna(value=0, inplace=True) # 0 = no item interaction / dislike?\n",
    "\n",
    "df_play.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and testing different recommender systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "\n",
    "Split the data into a train and test set. Here I employ an approach where I randomly select one purchased/played game for each user and add it to the hold-out test set (similar to the approach employed in [this article](https://medium.com/@teddywang0202/implicit-feedback-recommendation-system-ii-collaborative-filtering-27be600197f1) and [this tutorial](https://www.kaggle.com/code/taruntiwarihp/recommender-system-deep-learning).\n",
    "\n",
    "All models will be evaluated by calculating the average hit rate for hold-out items (i.e., games). A hit is defined as a trained model recommending the held-out item to a user in the top N (here N = 10) list entries.\n",
    "\n",
    "> Note: In practice, this could be extended to a cross-validation approach with multiple train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70373\n",
      "4945\n"
     ]
    }
   ],
   "source": [
    "def LOO_split(user_item_mat, random_state):\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # define test set mask\n",
    "    test_set_mask = np.zeros(user_item_mat.shape, dtype=bool)\n",
    "\n",
    "\n",
    "    for user_idx in range(user_item_mat.shape[0]):\n",
    "\n",
    "        # randomly pick user interaction for test set\n",
    "        user_vec = np.nonzero(user_item_mat.iloc[user_idx])[0]\n",
    "        test_set_mask[user_idx,user_vec[np.random.randint(0,len(user_vec))]] = True\n",
    "\n",
    "    train_set = user_item_mat.mask(test_set_mask, other = 0)\n",
    "    test_set = user_item_mat.mask(np.invert(test_set_mask), other = 0)\n",
    "\n",
    "    return train_set, test_set\n",
    "\n",
    "\n",
    "df_play_train, df_play_test = LOO_split(df_play, random_state=0)\n",
    "\n",
    "# also save training set as binray likes/purchases (ignoring playtime information) since this is used to train some models\n",
    "df_play_train_bin = (df_play_train > 0).astype('float')\n",
    "\n",
    "print(np.count_nonzero(df_play_train))\n",
    "print(np.count_nonzero(df_play_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory-based CF\n",
    "\n",
    "Here I implement user-user and item-item CF algorithms using custom (very inefficient) code. Optionally, a k-NearestNeighbor algorithm can be employed but it in my implementation it doesn't seem to speed up computation time much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kNN setting for memory-based collaborative filtering algorithms\n",
    "kNN_toggle = False # use kNN or all users\n",
    "kNN_K = 50 # size of the neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### user-user CF\n",
    "\n",
    "Train and test user-user CF on binary purchases using [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) as a distance metric (using [this article](https://medium.com/@corymaklin/memory-based-collaborative-filtering-user-based-42b2679c6fb5) for reference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userID\n",
      "5250         1.000000\n",
      "106042595    0.774597\n",
      "82212295     0.670820\n",
      "23672423     0.632456\n",
      "97303314     0.632456\n",
      "105024602    0.632456\n",
      "112944877    0.632456\n",
      "123397302    0.632456\n",
      "141950398    0.632456\n",
      "142754561    0.632456\n",
      "155155363    0.632456\n",
      "Name: 5250, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# compute user-user similarity matrix\n",
    "\n",
    "user_similarity_matrix = pd.DataFrame(cosine_similarity(df_play_train_bin), index = df_play_train.index, columns = df_play_train.index) # similarity based on cosine\n",
    "\n",
    "# Lets get the top 11 similar users for one user\n",
    "print(user_similarity_matrix.iloc[0].nlargest(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Half-Life 2'], dtype='object', name='itemID')\n",
      "itemID\n",
      "Team Fortress 2                    0.402049\n",
      "Portal                             0.358219\n",
      "Half-Life 2 Episode Two            0.289386\n",
      "Half-Life 2 Episode One            0.264813\n",
      "Counter-Strike Source              0.261388\n",
      "Left 4 Dead 2                      0.253387\n",
      "Half-Life 2 Lost Coast             0.247939\n",
      "Portal 2                           0.246885\n",
      "Counter-Strike Global Offensive    0.230001\n",
      "Dota 2                             0.193229\n",
      "Name: 13336286, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# make recommendations for an example user\n",
    "\n",
    "user = 13336286 # The id of the user for whom we want to generate recommendations\n",
    "\n",
    "# Get the games the user has purchased (i..e, liked)\n",
    "known_user_likes = df_play_train.columns[df_play_train.loc[user] > 0]\n",
    "\n",
    "# Calculate the score.\n",
    "score = user_similarity_matrix[user].dot(df_play_train_bin).div(user_similarity_matrix[user].sum())\n",
    "\n",
    "# Remove the known likes from the recommendation.\n",
    "score = score.drop(known_user_likes)\n",
    "\n",
    "# Print the known likes and the top 10 recommendations.\n",
    "print(known_user_likes)\n",
    "print(score.nlargest(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4074823053589484"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test predictions for hold-out set\n",
    "hit = []\n",
    "\n",
    "for user in df_play_test.index:\n",
    "    \n",
    "    target_game = df_play_test.columns[np.nonzero(df_play_test.loc[user])[0]][0]\n",
    "    # Get the games the user has purchased (i..e, liked)\n",
    "    known_user_likes = df_play_train.columns[df_play_train.loc[user] > 0]\n",
    "\n",
    "    # Calculate the score.\n",
    "    if not kNN_toggle:\n",
    "        score = user_similarity_matrix[user].dot(df_play_train_bin).div(user_similarity_matrix[user].sum())\n",
    "    elif kNN_toggle:\n",
    "\n",
    "        neighbors = user_similarity_matrix[user].nlargest(kNN_K).index\n",
    "\n",
    "        neighbor_user_similarity_matrix = user_similarity_matrix.loc[neighbors, user]\n",
    "        neighbor_user_ratings = df_play_train_bin.loc[neighbors]\n",
    "\n",
    "        score = neighbor_user_similarity_matrix.dot(neighbor_user_ratings).div(neighbor_user_similarity_matrix.sum())\n",
    "\n",
    "    # Remove the known likes from the recommendation.\n",
    "    score = score.drop(known_user_likes)\n",
    "\n",
    "    # save prediction accuracy\n",
    "    hit.append(target_game in score.nlargest(10).index)\n",
    "\n",
    "np.mean(hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained recommender system recommends relevant items to about 40% of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### item-item CF\n",
    "\n",
    "Train and test item-item CF on binary purchases using [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) as a distance metric (I used [this article](https://medium.com/radon-dev/item-item-collaborative-filtering-with-binary-or-unary-data-e8f0b465b2c3) for reference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itemID\n",
      "BioShock                                              1.000000\n",
      "BioShock 2                                            0.340672\n",
      "Dishonored                                            0.195028\n",
      "Borderlands DLC Claptraps New Robot Revolution        0.190342\n",
      "BioShock Infinite Burial at Sea - Episode 2           0.190136\n",
      "Borderlands DLC The Secret Armory of General Knoxx    0.186435\n",
      "BioShock Infinite                                     0.183789\n",
      "Borderlands DLC Mad Moxxi's Underdome Riot            0.180608\n",
      "Portal 2                                              0.176974\n",
      "Borderlands DLC The Zombie Island of Dr. Ned          0.176870\n",
      "Aion                                                  0.175797\n",
      "Name: BioShock, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# normalize to user vectors by dividing elements by the magnitude of the user vector\n",
    "data_bin_train_norm = df_play_train_bin.divide(np.sqrt(np.square(df_play_train_bin).sum(axis=1)), axis=0)\n",
    "\n",
    "item_similarity_matrix = pd.DataFrame(cosine_similarity(data_bin_train_norm.T), index = df_play_train.columns, columns = df_play_train.columns) # similarity based on cosine\n",
    "\n",
    "# Lets get the top 11 similar games to BioShock\n",
    "print(item_similarity_matrix['BioShock'].nlargest(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Half-Life 2'], dtype='object', name='itemID')\n",
      "itemID\n",
      "City of Heroes                 0.446530\n",
      "Cosmophony                     0.204062\n",
      "Duke Nukem Forever             0.127892\n",
      "Aberoth                        0.127061\n",
      "Planets Under Attack           0.111485\n",
      "Zoombinis                      0.091379\n",
      "Half-Life 2 Episode Two        0.081368\n",
      "Half-Life Deathmatch Source    0.076602\n",
      "Half-Life 2 Episode One        0.074687\n",
      "Half-Life 2 Lost Coast         0.071576\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# make recommendations for an example user\n",
    "\n",
    "user = 13336286 # The id of the user for whom we want to generate recommendations\n",
    "\n",
    "# Get the games the user has purchased (i..e, liked)\n",
    "known_user_likes = df_play_train.columns[df_play_train.loc[user] > 0]\n",
    "\n",
    "# Calculate the score.\n",
    "score = item_similarity_matrix.dot(df_play_train.loc[user]).div(item_similarity_matrix.sum(axis=1))\n",
    "\n",
    "# Remove the known likes from the recommendation.\n",
    "score = score.drop(known_user_likes)\n",
    "\n",
    "# Print the known likes and the top 10 recommendations.\n",
    "print(known_user_likes)\n",
    "print(score.nlargest(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10434782608695652"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test predictions for hold-out set\n",
    "hit = []\n",
    "\n",
    "if kNN_toggle:\n",
    "    \n",
    "    # Construct a dictionary with the K closest neighbors (most similar) for each game.\n",
    "    game_neighbors = {}\n",
    "    for i in item_similarity_matrix.columns:\n",
    "        game_neighbors[i] = item_similarity_matrix[i].nlargest(kNN_K).index\n",
    "\n",
    "for user in df_play_test.index:\n",
    "\n",
    "    target_game = df_play_test.columns[np.nonzero(df_play_test.loc[user])[0]][0]\n",
    "    # Get the games the user has purchased (i..e, liked)\n",
    "    known_user_likes = df_play_train.columns[df_play_train.loc[user] > 0]\n",
    "\n",
    "    # Calculate the score.\n",
    "    if not kNN_toggle:\n",
    "\n",
    "        score = item_similarity_matrix.dot(data_bin_train_norm.loc[user]).div(item_similarity_matrix.sum(axis=1))\n",
    "        score = score.drop(known_user_likes)\n",
    "\n",
    "    elif kNN_toggle:\n",
    "\n",
    "        # Construct the neighbourhood from the most similar items to the\n",
    "        # ones the user has liked\n",
    "        user_game_neighbors = []\n",
    "        for k in known_user_likes:\n",
    "            user_game_neighbors.extend(game_neighbors[k])\n",
    "\n",
    "        user_game_neighbors = list(set(user_game_neighbors)) # drop duplicates\n",
    "\n",
    "        neighbor_item_similarity = item_similarity_matrix.loc[user_game_neighbors,user_game_neighbors]\n",
    "\n",
    "        # A user vector containing only the neighbourhood items and\n",
    "        # the known user likes.\n",
    "        \n",
    "        neighbor_user_ratings = data_bin_train_norm.loc[user,user_game_neighbors]\n",
    "\n",
    "        # maybe use sparse matrix to speed up computation?\n",
    "        score = neighbor_item_similarity.dot(neighbor_user_ratings).div(neighbor_item_similarity.sum(axis=1))\n",
    "\n",
    "        # Remove the known likes from the recommendation.\n",
    "        known_user_likes = list(set(known_user_likes) & set(user_game_neighbors)) # some items may already be reomved for small K\n",
    "        score = score.drop(known_user_likes)\n",
    "\n",
    "    # save prediction accuracy\n",
    "    hit.append(target_game in score.nlargest(10).index)\n",
    "\n",
    "np.mean(hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained recommender system recommends relevant items to about 10% of users. Quite poor and (surprisingly) much worse than the user-user model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-based CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I implement and test different model-based algorithms using custom code and the [implicit](https://github.com/benfred/implicit) python library. I was particularly interested in trying an Alternative Least-Squares model (described in [this paper](http://yifanhu.net/PUB/cf.pdf), which has been), which takes into account implicit user behavior as a proxy for confidence in how a user may like an item. In the present dataset, I use users' playtime information as an implicit indicator for liking.\n",
    "\n",
    "Some useful background references for application of these models to implicit data:\n",
    " - [this Medium article](https://medium.com/@teddywang0202/implicit-feedback-recommendation-system-ii-collaborative-filtering-27be600197f1)\n",
    " - the [implicit library docs](https://benfred.github.io/implicit/index.html), especially the tutorial\n",
    "\n",
    "\n",
    "> Note: Other interesting libraries for model-based CF are [LightFM](https://github.com/lyst/lightfm) and [surprise](https://surprise.readthedocs.io/en/stable/index.html) (although the latter seems more tailored to explicit feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Singular Value Decomposition (SVD)\n",
    "\n",
    "Train and evaluate a model based SVD of the binary item-user matrix (using [scipy](https://docs.scipy.org/doc/scipy/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD with U shape:(4945,10), S_mat shape:(10,10), Vt shape:(10,5126)\n"
     ]
    }
   ],
   "source": [
    "U, S, Vt = svds(df_play_train_bin.to_numpy(), k = 10) # should tune number of factors to keep\n",
    "S_mat = np.diag(S)\n",
    "rating_matrix_hat = U@S_mat@Vt\n",
    "rating_matrix_hat = pd.DataFrame(rating_matrix_hat,index=df_play_train.index,columns=df_play_train.columns)\n",
    "\n",
    "print('SVD with U shape:(%d,%d), S_mat shape:(%d,%d), Vt shape:(%d,%d)'\n",
    "      %(U.shape[0],U.shape[1],S_mat.shape[0],S_mat.shape[1],Vt.shape[0],Vt.shape[1])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Half-Life 2'], dtype='object', name='itemID')\n",
      "itemID\n",
      "Portal                             0.076181\n",
      "Team Fortress 2                    0.071413\n",
      "Portal 2                           0.052020\n",
      "Counter-Strike Source              0.050250\n",
      "Half-Life 2 Episode Two            0.044395\n",
      "Left 4 Dead 2                      0.040557\n",
      "Fallout New Vegas Honest Hearts    0.040425\n",
      "Half-Life 2 Episode One            0.040131\n",
      "Fallout New Vegas Dead Money       0.039981\n",
      "Half-Life 2 Lost Coast             0.039092\n",
      "Name: 13336286, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# make recommendations for an example user\n",
    "\n",
    "user = 13336286 # The id of the user for whom we want to generate recommendations\n",
    "\n",
    "# Get the games the user has purchased (i..e, liked)\n",
    "known_user_likes = df_play_train.columns[df_play_train.loc[user] > 0]\n",
    "\n",
    "# Remove the known likes from the recommendation.\n",
    "score = rating_matrix_hat.loc[user]\n",
    "score = score.drop(known_user_likes)\n",
    "\n",
    "# Print the known likes and the top 10 recommendations.\n",
    "print(known_user_likes)\n",
    "print(score.nlargest(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3302325581395349"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test predictions for hold-out set\n",
    "hit = []\n",
    "\n",
    "for user in df_play_test.index:\n",
    "\n",
    "    target_game = df_play_test.columns[np.nonzero(df_play_test.loc[user])[0]][0]\n",
    "    # Get the games the user has purchased (i..e, liked)\n",
    "    known_user_likes = df_play_train.columns[df_play_train.loc[user] > 0]\n",
    "\n",
    "    # Remove the known likes from the recommendation.\n",
    "    score = rating_matrix_hat.loc[user]\n",
    "    score = score.drop(known_user_likes)\n",
    "\n",
    "    hit.append(target_game in score.nlargest(10).index)\n",
    "\n",
    "np.mean(hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained recommender system recommends relevant items to about 33% of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Matrix Factorization (LMF)\n",
    "\n",
    "Train and test LMF model on binary user-item matrix as implemented in implicit library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac00e396324403fba1dfd0ded2b9517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Train logistic matrix factorization model\n",
    "from implicit.cpu.lmf import LogisticMatrixFactorization\n",
    "\n",
    "# train model on binary data\n",
    "\n",
    "df_play_train_bin_csr = sparse.csr_matrix(df_play_train_bin)\n",
    "\n",
    "LMF_model = LogisticMatrixFactorization(random_state=0)\n",
    "LMF_model.fit(df_play_train_bin.to_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3146612740141557"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test predictions for hold-out set\n",
    "hit = []\n",
    "\n",
    "for user_idx in range(df_play_test.shape[0]): # user index is row index not label!\n",
    "\n",
    "    target_game = df_play_test.columns[np.nonzero(df_play_test.iloc[user_idx])[0]][0]\n",
    "    items, scores = LMF_model.recommend(user_idx, df_play_train_bin_csr[user_idx], N=10, filter_already_liked_items=True)\n",
    "\n",
    "    hit.append(target_game in df_play_train.columns[items])\n",
    "\n",
    "np.mean(hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained recommender system recommends relevant items to about 31% of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative Least-Squares (ALS)\n",
    "\n",
    "Train and test ALS model as implemented in implicit library. Note that playtimes are first transformed to confidence weights (see [implicit doc tutorial](https://benfred.github.io/implicit/tutorial_lastfm.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13.77227431, 155.19110987,  65.84466933, ...,  32.28851242,\n",
       "         1.06724704,   4.59993955])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert playtimes to confidence weights\n",
    "\n",
    "# weight the matrix, both to reduce impact of users that have played the games for a very long time\n",
    "# and to reduce the weight given to popular games\n",
    "\n",
    "df_play_train_csr = sparse.csr_matrix(df_play_train)\n",
    "data_play_train = bm25_weight(df_play_train_csr.T.tocsr(), K1=100, B=0.8) # transpose to apply weight over items\n",
    "data_play_train = data_play_train.T.tocsr() # backtranspose\n",
    "\n",
    "data_play_train.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53c1c95238942aba200a7fe46834aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train ALS model\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "ALS_model = AlternatingLeastSquares(factors=64, regularization=0.05, alpha=2.0)\n",
    "ALS_model.fit(data_play_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 13336286\n",
      "Index(['Half-Life 2'], dtype='object', name='itemID')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Half-Life 2 Episode One</td>\n",
       "      <td>0.459758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Half-Life 2 Episode Two</td>\n",
       "      <td>0.453534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Half-Life 2 Lost Coast</td>\n",
       "      <td>0.433904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Portal</td>\n",
       "      <td>0.287283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Half-Life Source</td>\n",
       "      <td>0.202165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Portal 2</td>\n",
       "      <td>0.177300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Half-Life 2 Deathmatch</td>\n",
       "      <td>0.166800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sid Meier's Civilization V</td>\n",
       "      <td>0.163768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Counter-Strike Source</td>\n",
       "      <td>0.162636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Half-Life Blue Shift</td>\n",
       "      <td>0.155676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       itemID     score\n",
       "0     Half-Life 2 Episode One  0.459758\n",
       "1     Half-Life 2 Episode Two  0.453534\n",
       "2      Half-Life 2 Lost Coast  0.433904\n",
       "3                      Portal  0.287283\n",
       "4            Half-Life Source  0.202165\n",
       "5                    Portal 2  0.177300\n",
       "6      Half-Life 2 Deathmatch  0.166800\n",
       "7  Sid Meier's Civilization V  0.163768\n",
       "8       Counter-Strike Source  0.162636\n",
       "9        Half-Life Blue Shift  0.155676"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get recommendations for a example user\n",
    "user_idx = 145 # row index, not label!\n",
    "items, scores = ALS_model.recommend(user_idx, data_play_train[user_idx], N=10, filter_already_liked_items=True)\n",
    "\n",
    "# Use pandas to display the output in a table\n",
    "print('User ' + str(df_play_train.index[user_idx]))\n",
    "print(df_play_train.columns[df_play_train.iloc[user_idx] > 0]) # known user plays\n",
    "pd.DataFrame({\"itemID\": df_play_train.columns[items], \"score\": scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BioShock</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BioShock 2</td>\n",
       "      <td>0.561415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BioShock Infinite</td>\n",
       "      <td>0.512336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X-COM Enforcer</td>\n",
       "      <td>0.501144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fallout 3 - Game of the Year Edition</td>\n",
       "      <td>0.475707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Borderlands DLC Claptraps New Robot Revolution</td>\n",
       "      <td>0.450050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Borderlands DLC Mad Moxxi's Underdome Riot</td>\n",
       "      <td>0.446691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Borderlands DLC The Secret Armory of General K...</td>\n",
       "      <td>0.444916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Portal</td>\n",
       "      <td>0.441231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Assassin's Creed</td>\n",
       "      <td>0.439967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                game     score\n",
       "0                                           BioShock  1.000000\n",
       "1                                         BioShock 2  0.561415\n",
       "2                                  BioShock Infinite  0.512336\n",
       "3                                     X-COM Enforcer  0.501144\n",
       "4               Fallout 3 - Game of the Year Edition  0.475707\n",
       "5     Borderlands DLC Claptraps New Robot Revolution  0.450050\n",
       "6         Borderlands DLC Mad Moxxi's Underdome Riot  0.446691\n",
       "7  Borderlands DLC The Secret Armory of General K...  0.444916\n",
       "8                                             Portal  0.441231\n",
       "9                                   Assassin's Creed  0.439967"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display similar items for a specific game\n",
    "item_idx=df_play_train.columns.get_loc(\"BioShock\") # item index not label!\n",
    "\n",
    "items, scores= ALS_model.similar_items(item_idx)\n",
    "\n",
    "# display the results using pandas for nicer formatting\n",
    "pd.DataFrame({\"game\": df_play_train.columns[items], \"score\": scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3290192113245703"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test predictions for hold-out set\n",
    "hit = []\n",
    "\n",
    "for user_idx in range(df_play_test.shape[0]): # user index is row index not label!\n",
    "\n",
    "    target_game = df_play_test.columns[np.nonzero(df_play_test.iloc[user_idx])[0]][0]\n",
    "    items, scores = ALS_model.recommend(user_idx, data_play_train[user_idx], N=10, filter_already_liked_items=True)\n",
    "\n",
    "    hit.append(target_game in df_play_train.columns[items])\n",
    "\n",
    "np.mean(hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained recommender system recommends relevant items to about 32% of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Personalized Ranking (BPR)\n",
    "\n",
    "Train and test BPR model as implemented in implicit library. Note that I use the same confidence-weight user-item matrix as for the ALS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da33226a093141ce9af3a514285e7b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Train BPR model\n",
    "from implicit.cpu.bpr import BayesianPersonalizedRanking\n",
    "\n",
    "BPR_model = BayesianPersonalizedRanking(random_state=0)\n",
    "BPR_model.fit(data_play_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37451971688574315"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test predictions for hold-out set\n",
    "hit = []\n",
    "\n",
    "for user_idx in range(df_play_test.shape[0]): # user index is row index not label!\n",
    "\n",
    "    target_game = df_play_test.columns[np.nonzero(df_play_test.iloc[user_idx])[0]][0]\n",
    "    items, scores = BPR_model.recommend(user_idx, data_play_train[user_idx], N=10, filter_already_liked_items=True)\n",
    "\n",
    "    hit.append(target_game in df_play_train.columns[items])\n",
    "\n",
    "np.mean(hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained recommender system recommends relevant items to about 37% of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interim conclusions\n",
    "\n",
    "The memory-based user-user CF surprisingly seems to perform best on the hold-out test set in recommending relevant games to users (about 40% hit rate). Note, however, that this approach is very computation demanding and likely scales poorly. The best model-based algorithm seems to be BPR. The ALS model of interest performs surprisingly poorly only having a hit rate of about 32% (similar to other matrix factorization approaches)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
